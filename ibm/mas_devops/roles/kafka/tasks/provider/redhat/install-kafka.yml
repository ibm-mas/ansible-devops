---
# 1. Load default storage classes (if not provided by the user)
# -----------------------------------------------------------------------------
- include_tasks: tasks/determine-storage-classes.yml

# 2. Lookup the packagemanifest for amq-streams / strimzi
# -----------------------------------------------------------------------------
- name: Get {{ kafka_operator_name }} package manifest
  kubernetes.core.k8s_info:
    api_version: packages.operators.coreos.com/v1
    kind: PackageManifest
    name: "{{ kafka_operator_name }}"
    namespace: openshift-marketplace # Note: A namespace must be provided when calling packages.operators.coreos.com/v1
  register: kafka_manifest

- name: Assert that PackageManifest exists
  ansible.builtin.assert:
    that:
      - kafka_manifest is defined
      - kafka_manifest.resources is defined
      - kafka_manifest.resources | length == 1
    fail_msg: "PackageManifest not found: {{ kafka_operator_name }}"

- name: Set the subscription information
  set_fact:
    kafka_source: "{{ kafka_manifest.resources[0].status.catalogSource }}"
    kafka_source_namespace: "{{ kafka_manifest.resources[0].status.catalogSourceNamespace }}"
    kafka_default_channel: "{{ kafka_manifest.resources[0].status.defaultChannel }}"

# 3. Detect if the cluster supports GrafanaDashboards
# ---------------------------------------------------
- name: Get cluster info
  kubernetes.core.k8s_cluster_info:
  register: api_status
  no_log: true

- name: Determine cluster grafana capabilities
  set_fact:
    supports_grafanav4: "{{
      api_status is defined and
      api_status.apis is defined and
      api_status.apis['integreatly.org/v1alpha1'] is defined }}"
    supports_grafanav5: "{{
      api_status is defined and
      api_status.apis is defined and
      api_status.apis['grafana.integreatly.org/v1beta1'] is defined }}"

# 4. Lookup any existing kafka user in the kafka namespace to use the same password
# ---------------------------------------------------------------------------------
- name: "Lookup any existing Kafka User Secret"
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Secret
    name: "{{ kafka_user_name }}"
    namespace: "{{ kafka_namespace }}"
  register: kafka_user_secret_lookup

- name: "Set kafka user password fact based on any existing secret"
  set_fact:
    kafka_user_password: "{{ kafka_user_secret_lookup.resources[0].data.password | b64decode }}"
  when:
    - kafka_user_secret_lookup is defined
    - kafka_user_secret_lookup.resources[0].data.password is defined

# 5. Provide debug
# -----------------------------------------------------------------------------
- name: "Debug information"
  debug:
    msg:
      - "Catalog source  ....................... {{ kafka_source }}"
      - "Catalog source namespace .............. {{ kafka_source_namespace }}"
      - "Default channel ....................... {{ kafka_default_channel }}"
      - "Kafka namespace ....................... {{ kafka_namespace }}"
      - "Kafka operator name ................... {{ kafka_operator_name }}"
      - "Kafka version ......................... {{ kafka_version }}"
      - "Kafka cluster name .................... {{ kafka_cluster_name }}"
      - "Kafka cluster size .................... {{ kafka_cluster_size }}"
      - "Kafka kafka storage class ............. {{ kafka_storage_class }}"
      - "Kafka kafka storage size .............. {{ kafka_storage_size }}"
      - "Kafka zookeeper storage class ......... {{ zookeeper_storage_class }}"
      - "Kafka zookeeper storage size .......... {{ zookeeper_storage_size }}"
      - "Kafka MAS user ........................ {{ kafka_user_name }}"
      - "Cluster supports grafana v4 ........... {{ supports_grafanav4 }}"
      - "Cluster supports grafana v5 ........... {{ supports_grafanav5 }}"

# 6. Install Kafka operator
# -----------------------------------------------------------------------------
- name: "Install {{ kafka_operator_name }} subscription"
  kubernetes.core.k8s:
    apply: yes
    template: templates/redhat/subscription.yml.j2

# 7. Wait until the Kafka CRD is available
# -----------------------------------------------------------------------------
- name: "Wait until the Kafka CRD is available"
  include_tasks: "{{ role_path }}/../../common_tasks/wait_for_crd.yml"
  vars:
    crd_name: kafkas.kafka.strimzi.io

# 8. Lookup Kafka supported versions based upon the Kafka provider operator version
# -----------------------------------------------------------------------------
- name: "Lookup Kafka supported versions based upon the Kafka provider operator version"
  include_tasks: "tasks/provider/redhat/lookup-supported-kafka-versions.yml"
  when: kafka_provider == 'strimzi'

# 9. Create logging/monitoring configmaps and PodMonitor custom resources
# -----------------------------------------------------------------------------
- name: "Create Kafka logging configmap"
  kubernetes.core.k8s:
    apply: yes
    template: "templates/redhat/logging-configmap.yml.j2"

- name: "Create Kafka monitoring configmap"
  kubernetes.core.k8s:
    apply: yes
    template: "templates/redhat/metrics-configmap.yml.j2"

- name: "Create Kafka PodMonitor custom resources"
  kubernetes.core.k8s:
    apply: yes
    template: "templates/redhat/podmonitor.yml.j2"

# 10. Deploy the cluster
# -----------------------------------------------------------------------------
- name: "Create Kafka Cluster"
  kubernetes.core.k8s:
    apply: yes
    template: "templates/redhat/clusters/{{ kafka_cluster_size }}.yml.j2"

# 11. Wait until the KafkaUser CRD is available
# -----------------------------------------------------------------------------
- name: "Wait until the KafkaUser CRD is available"
  include_tasks: "{{ role_path }}/../../common_tasks/wait_for_crd.yml"
  vars:
    crd_name: kafkausers.kafka.strimzi.io

# 12. Create the MAS user
# -----------------------------------------------------------------------------
- name: "Create Kafka User"
  kubernetes.core.k8s:
    apply: yes
    template: templates/redhat/masuser.yml.j2

# 13. Create Grafana dashboards for Kafka monitoring
# -----------------------------------------------------------------------------
- name: "Create Kafka monitoring dashboards"
  kubernetes.core.k8s:
    apply: yes
    template: "{{ item }}"
  with_fileglob:
    - "templates/redhat/dashboards/*.yml.j2"
  when: supports_grafanav4

- name: "Create Kafka monitoring dashboards"
  kubernetes.core.k8s:
    apply: yes
    template: "{{ item }}"
  with_fileglob:
    - "templates/redhat/dashboards-v5/*.yml.j2"
  when: supports_grafanav5

# 14. Lookup details
# -----------------------------------------------------------------------------
# We have seen instances where the Kafka cluster is reported as Ready but
# the necessary fields in the status resource are not set yet so we retry until
# the expected fields are set as well
- name: "Wait for Kafka Resource to be ready (60s delay)"
  kubernetes.core.k8s_info:
    api_version: kafka.strimzi.io/v1beta2
    kind: Kafka
    name: "{{ kafka_cluster_name }}"
    namespace: "{{ kafka_namespace }}"
  register: kafka_cluster_lookup
  retries: 30 # will wait for up to 30 minutes for the listener information to be added to the status sub-resource
  delay: 60 # seconds
  until:
    - kafka_cluster_lookup.resources is defined
    - kafka_cluster_lookup.resources | length > 0
    - kafka_cluster_lookup.resources[0].status is defined
    - kafka_cluster_lookup.resources[0].status.conditions | selectattr('type', 'equalto', 'Ready') | map(attribute='status') | list | length > 0
    - kafka_cluster_lookup.resources[0].status.conditions | selectattr('type', 'equalto', 'Ready')| map(attribute='status') | list | first == "True"
    - kafka_cluster_lookup.resources[0].status.listeners is defined
    - kafka_cluster_lookup.resources[0].status.listeners | length > 0

- name: "Lookup Kafka Secret"
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Secret
    name: "{{ kafka_user_name }}"
    namespace: "{{ kafka_namespace }}"
  register: kafka_user_secret_lookup

- name: "Set new facts based on resource lookups"
  set_fact:
    kafka_bootstrap_host: "{{ kafka_cluster_lookup.resources[0].status.listeners[1].addresses[0].host }}"
    kafka_bootstrap_cert: "{{ kafka_cluster_lookup.resources[0].status.listeners[1].certificates[0] }}"
    kafka_int_bootstrap_host: "{{ kafka_cluster_lookup.resources[0].status.listeners[0].addresses[0].host }}"
    kafka_int_bootstrap_cert: "{{ kafka_cluster_lookup.resources[0].status.listeners[0].certificates[0] }}"
    kafka_user_password: "{{ kafka_user_secret_lookup.resources[0].data.password | b64decode }}"

- name: "Debug new facts"
  debug:
    msg:
      - "External listener:"
      - "  Bootstrap host ............... {{ kafka_bootstrap_host }}"
      - "  Bootstrap cert ............... {{ kafka_bootstrap_cert }}"
      - "Internal listener:"
      - "  Bootstrap host ............... {{ kafka_int_bootstrap_host }}"
      - "  Bootstrap cert ............... {{ kafka_int_bootstrap_cert }}"
      - "MAS user password ............ {{ kafka_user_password }}"

# 15. Create KafkaCfg for MAS (if mas_instance_id & mas_config_dir are set)
# -----------------------------------------------------------------------------
- name: Debug KafkaCfg creation properties
  when:
    - mas_instance_id is defined
    - mas_instance_id != ""
    - mas_config_dir is defined
    - mas_config_dir != ""
  debug:
    msg:
      - "MAS Instance ID .............. {{ mas_instance_id }}"
      - "MAS Config directory ......... {{ mas_config_dir }}"

- name: Save KafkaCfg to filesytem
  when:
    - mas_instance_id is defined
    - mas_instance_id != ""
    - mas_config_dir is defined
    - mas_config_dir != ""
  ansible.builtin.template:
    src: redhat/kafkacfg.yml.j2
    dest: "{{ mas_config_dir }}/kafka-{{ kafka_cluster_name }}-{{ kafka_namespace }}.yml"
    mode: "664"
